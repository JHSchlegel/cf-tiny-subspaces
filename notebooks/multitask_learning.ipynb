{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-task Training Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive implementation of multi-task joint learning, applied to training models such as `MLP` and `CNN` on datasets like `Permuted MNIST` and `Split CIFAR-10/100`.\n",
    "\n",
    "While the primary focus of this study is on Continual Learning, this section takes a different approach by leveraging the entire dataset, processed at once altogether/in sequential chunks rather than task-by-task progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Presets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and logging setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "import warnings\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from modules.JointTrainer import JointTrainer\n",
    "from modules.mlp import MLP\n",
    "from modules.cnn import CNN\n",
    "from utils.data_utils.permuted_mnist import PermutedMNIST\n",
    "from utils.data_utils.sequential_CIFAR import CL_CIFAR10, CL_CIFAR100\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up logging:\n",
    "log_dir = \"../logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_filename = os.path.join(\n",
    "    log_dir, f'multitask_training_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.log'\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Function for Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main training function\n",
    "def main(config: DictConfig) -> None:\n",
    "    \"\"\"\n",
    "    Main training function for Permuted MNIST multitask joint training.\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object loaded from YAML.\n",
    "\n",
    "    \"\"\"\n",
    "    # Set the save directory\n",
    "    save_dir = config.hydra.run.dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    logging.info(f\"Saving results to {save_dir}\")\n",
    "\n",
    "    # Create permuted MNIST dataset\n",
    "    pmnist = PermutedMNIST(\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        seed=config.data.seed\n",
    "    )\n",
    "    pmnist.setup_tasks(\n",
    "        batch_size=config.data.batch_size,\n",
    "        data_root=config.data.data_root,\n",
    "        num_workers=config.data.num_workers,\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = MLP(\n",
    "        input_dim=config.model.input_dim,\n",
    "        output_dim=config.model.output_dim,\n",
    "        hidden_dim=config.model.hidden_dim,\n",
    "    )\n",
    "    model.to(config.training.device)\n",
    "\n",
    "    # Initialize loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize optimizer\n",
    "    # Note that we do not need customized SubspaceSGD anymore;\n",
    "    # the standard SGD will do the job\n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=config.optimizer.lr,\n",
    "        momentum=config.optimizer.momentum,\n",
    "        weight_decay=config.optimizer.weight_decay,\n",
    "        nesterov=config.optimizer.nesterov,\n",
    "    )\n",
    "\n",
    "    # Initialize joint trainer\n",
    "    trainer = JointTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        save_dir=save_dir,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        num_epochs=config.training.num_epochs,\n",
    "        log_interval=config.training.log_interval,\n",
    "        eval_freq=config.training.eval_freq,\n",
    "        task_il=True,  # Permuted MNIST is task-IL\n",
    "        checkpoint_freq=config.training.checkpoint_freq,\n",
    "        seed=config.training.seed,\n",
    "        scheduler=None,\n",
    "        device=config.training.device,\n",
    "        use_wandb=config.wandb.enabled,\n",
    "        wandb_project=config.wandb.project,\n",
    "        wandb_config=OmegaConf.to_container(config, resolve=True),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Train and evaluate jointly on all tasks\n",
    "        test_accuracies, test_losses = trainer.train_and_evaluate(\n",
    "            cl_dataset=pmnist\n",
    "        )\n",
    "\n",
    "        # Calculate final metrics\n",
    "        final_accuracies = [test_accuracies[task_id][-1] for task_id in range(config.data.num_tasks)]\n",
    "        final_avg_accuracy = np.mean(final_accuracies)\n",
    "\n",
    "        # Log final results\n",
    "        logging.info(\"\\n=== Final Results ===\")\n",
    "        for task_id in range(config.data.num_tasks):\n",
    "            logging.info(f\"Task {task_id + 1} Accuracy: {final_accuracies[task_id]:.2f}%\")\n",
    "        logging.info(f\"Final Average Accuracy: {final_avg_accuracy:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training and evaluation for Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 09:32:57,642 - INFO - Saving results to c:/Users/rufat/cf-tiny-subspaces/notebooks/../results/permuted_mnist/subspace-None/k-10/batch_size-128/hidden_dim-100/lr-0.01/seed-42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrasadlii\u001b[0m (\u001b[33mml-projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\wandb\\run-20250107_093345-ztaa3e1a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-projects/permuted_mnist_None/runs/ztaa3e1a' target=\"_blank\">solar-plasma-1</a></strong> to <a href='https://wandb.ai/ml-projects/permuted_mnist_None' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-projects/permuted_mnist_None' target=\"_blank\">https://wandb.ai/ml-projects/permuted_mnist_None</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-projects/permuted_mnist_None/runs/ztaa3e1a' target=\"_blank\">https://wandb.ai/ml-projects/permuted_mnist_None/runs/ztaa3e1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 09:33:48,620 - INFO - Starting joint training on 10 tasks\n",
      "Epoch 1/5: 100%|██████████| 469/469 [00:24<00:00, 18.92it/s, loss=6.8284, acc=78.59%] \n",
      "2025-01-07 09:34:26,871 - INFO - \n",
      "Epoch 1/5\n",
      "2025-01-07 09:34:26,876 - INFO - Average Loss: 1.4087\n",
      "2025-01-07 09:34:26,877 - INFO - Average Accuracy: 56.59%\n",
      "2025-01-07 09:34:26,878 - INFO - Time: 31.89s\n",
      "Evaluating Task 0: 100%|██████████| 79/79 [00:04<00:00, 16.71it/s]\n",
      "Evaluating Task 1: 100%|██████████| 79/79 [00:04<00:00, 16.36it/s]\n",
      "Evaluating Task 2: 100%|██████████| 79/79 [00:04<00:00, 15.85it/s]\n",
      "Evaluating Task 3: 100%|██████████| 79/79 [00:04<00:00, 17.21it/s]\n",
      "Evaluating Task 4: 100%|██████████| 79/79 [00:04<00:00, 16.56it/s]\n",
      "Evaluating Task 5: 100%|██████████| 79/79 [00:04<00:00, 16.30it/s]\n",
      "Evaluating Task 6: 100%|██████████| 79/79 [00:04<00:00, 17.14it/s]\n",
      "Evaluating Task 7: 100%|██████████| 79/79 [00:04<00:00, 16.13it/s]\n",
      "Evaluating Task 8: 100%|██████████| 79/79 [00:04<00:00, 16.26it/s]\n",
      "Evaluating Task 9: 100%|██████████| 79/79 [00:04<00:00, 16.69it/s]\n",
      "2025-01-07 09:35:14,798 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:35:14,802 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_0.pt\n",
      "2025-01-07 09:35:14,806 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_0.pt\n",
      "Epoch 2/5: 100%|██████████| 469/469 [00:24<00:00, 18.87it/s, loss=4.2744, acc=88.12%]\n",
      "2025-01-07 09:35:52,899 - INFO - \n",
      "Epoch 2/5\n",
      "2025-01-07 09:35:52,900 - INFO - Average Loss: 0.5251\n",
      "2025-01-07 09:35:52,902 - INFO - Average Accuracy: 84.05%\n",
      "2025-01-07 09:35:52,902 - INFO - Time: 31.61s\n",
      "Evaluating Task 0: 100%|██████████| 79/79 [00:04<00:00, 16.03it/s]\n",
      "Evaluating Task 1: 100%|██████████| 79/79 [00:04<00:00, 16.05it/s]\n",
      "Evaluating Task 2: 100%|██████████| 79/79 [00:04<00:00, 16.41it/s]\n",
      "Evaluating Task 3: 100%|██████████| 79/79 [00:04<00:00, 16.16it/s]\n",
      "Evaluating Task 4: 100%|██████████| 79/79 [00:04<00:00, 15.96it/s]\n",
      "Evaluating Task 5: 100%|██████████| 79/79 [00:04<00:00, 16.27it/s]\n",
      "Evaluating Task 6: 100%|██████████| 79/79 [00:04<00:00, 16.61it/s]\n",
      "Evaluating Task 7: 100%|██████████| 79/79 [00:04<00:00, 16.67it/s]\n",
      "Evaluating Task 8: 100%|██████████| 79/79 [00:04<00:00, 16.00it/s]\n",
      "Evaluating Task 9: 100%|██████████| 79/79 [00:04<00:00, 16.82it/s]\n",
      "2025-01-07 09:36:41,464 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:36:41,465 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_1.pt\n",
      "2025-01-07 09:36:41,468 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_1.pt\n",
      "Epoch 3/5: 100%|██████████| 469/469 [00:23<00:00, 19.63it/s, loss=3.8733, acc=88.83%]\n",
      "2025-01-07 09:37:17,972 - INFO - \n",
      "Epoch 3/5\n",
      "2025-01-07 09:37:17,976 - INFO - Average Loss: 0.4298\n",
      "2025-01-07 09:37:17,977 - INFO - Average Accuracy: 87.17%\n",
      "2025-01-07 09:37:17,978 - INFO - Time: 30.25s\n",
      "Evaluating Task 0: 100%|██████████| 79/79 [00:04<00:00, 16.84it/s]\n",
      "Evaluating Task 1: 100%|██████████| 79/79 [00:04<00:00, 16.53it/s]\n",
      "Evaluating Task 2: 100%|██████████| 79/79 [00:04<00:00, 17.29it/s]\n",
      "Evaluating Task 3: 100%|██████████| 79/79 [00:04<00:00, 15.88it/s]\n",
      "Evaluating Task 4: 100%|██████████| 79/79 [00:04<00:00, 16.77it/s]\n",
      "Evaluating Task 5: 100%|██████████| 79/79 [00:04<00:00, 17.95it/s]\n",
      "Evaluating Task 6: 100%|██████████| 79/79 [00:04<00:00, 17.63it/s]\n",
      "Evaluating Task 7: 100%|██████████| 79/79 [00:05<00:00, 14.80it/s]\n",
      "Evaluating Task 8: 100%|██████████| 79/79 [00:05<00:00, 15.50it/s]\n",
      "Evaluating Task 9: 100%|██████████| 79/79 [00:05<00:00, 15.42it/s]\n",
      "2025-01-07 09:38:06,219 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:38:06,222 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_2.pt\n",
      "2025-01-07 09:38:06,226 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_2.pt\n",
      "Epoch 4/5: 100%|██████████| 469/469 [00:36<00:00, 12.87it/s, loss=3.5283, acc=89.06%]\n",
      "2025-01-07 09:38:56,567 - INFO - \n",
      "Epoch 4/5\n",
      "2025-01-07 09:38:56,572 - INFO - Average Loss: 0.3782\n",
      "2025-01-07 09:38:56,573 - INFO - Average Accuracy: 88.76%\n",
      "2025-01-07 09:38:56,573 - INFO - Time: 43.49s\n",
      "Evaluating Task 0: 100%|██████████| 79/79 [00:04<00:00, 16.57it/s]\n",
      "Evaluating Task 1: 100%|██████████| 79/79 [00:05<00:00, 14.67it/s]\n",
      "Evaluating Task 2: 100%|██████████| 79/79 [00:04<00:00, 16.05it/s]\n",
      "Evaluating Task 3: 100%|██████████| 79/79 [00:04<00:00, 16.99it/s]\n",
      "Evaluating Task 4: 100%|██████████| 79/79 [00:04<00:00, 16.72it/s]\n",
      "Evaluating Task 5: 100%|██████████| 79/79 [00:04<00:00, 18.15it/s]\n",
      "Evaluating Task 6: 100%|██████████| 79/79 [00:04<00:00, 16.95it/s]\n",
      "Evaluating Task 7: 100%|██████████| 79/79 [00:04<00:00, 18.26it/s]\n",
      "Evaluating Task 8: 100%|██████████| 79/79 [00:04<00:00, 15.96it/s]\n",
      "Evaluating Task 9: 100%|██████████| 79/79 [00:04<00:00, 18.14it/s]\n",
      "2025-01-07 09:39:43,726 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:39:43,728 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_3.pt\n",
      "2025-01-07 09:39:43,729 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_3.pt\n",
      "Epoch 5/5: 100%|██████████| 469/469 [01:17<00:00,  6.07it/s, loss=3.1039, acc=90.70%]\n",
      "2025-01-07 09:41:16,028 - INFO - \n",
      "Epoch 5/5\n",
      "2025-01-07 09:41:16,033 - INFO - Average Loss: 0.3341\n",
      "2025-01-07 09:41:16,034 - INFO - Average Accuracy: 90.09%\n",
      "2025-01-07 09:41:16,035 - INFO - Time: 83.10s\n",
      "Evaluating Task 0: 100%|██████████| 79/79 [00:03<00:00, 22.63it/s]\n",
      "Evaluating Task 1: 100%|██████████| 79/79 [00:03<00:00, 23.63it/s]\n",
      "Evaluating Task 2: 100%|██████████| 79/79 [00:03<00:00, 22.54it/s]\n",
      "Evaluating Task 3: 100%|██████████| 79/79 [00:03<00:00, 21.79it/s]\n",
      "Evaluating Task 4: 100%|██████████| 79/79 [00:03<00:00, 23.56it/s]\n",
      "Evaluating Task 5: 100%|██████████| 79/79 [00:03<00:00, 23.40it/s]\n",
      "Evaluating Task 6: 100%|██████████| 79/79 [00:04<00:00, 18.21it/s]\n",
      "Evaluating Task 7: 100%|██████████| 79/79 [00:03<00:00, 21.40it/s]\n",
      "Evaluating Task 8: 100%|██████████| 79/79 [00:03<00:00, 23.09it/s]\n",
      "Evaluating Task 9: 100%|██████████| 79/79 [00:03<00:00, 22.56it/s]\n",
      "2025-01-07 09:41:51,733 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:41:51,734 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_4.pt\n",
      "2025-01-07 09:41:51,736 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\permuted_mnist\\subspace-None\\k-10\\batch_size-128\\hidden_dim-100\\lr-0.01\\seed-42\\models\\model_epoch_4.pt\n",
      "2025-01-07 09:41:51,738 - INFO - \n",
      "Training completed in 483.12s\n",
      "2025-01-07 09:41:51,739 - INFO - Best average accuracy: 91.09%\n",
      "2025-01-07 09:41:51,745 - INFO - \n",
      "=== Final Results ===\n",
      "2025-01-07 09:41:51,747 - INFO - Task 1 Accuracy: 90.78%\n",
      "2025-01-07 09:41:51,748 - INFO - Task 2 Accuracy: 91.13%\n",
      "2025-01-07 09:41:51,748 - INFO - Task 3 Accuracy: 91.22%\n",
      "2025-01-07 09:41:51,750 - INFO - Task 4 Accuracy: 91.13%\n",
      "2025-01-07 09:41:51,750 - INFO - Task 5 Accuracy: 90.76%\n",
      "2025-01-07 09:41:51,751 - INFO - Task 6 Accuracy: 91.40%\n",
      "2025-01-07 09:41:51,752 - INFO - Task 7 Accuracy: 91.03%\n",
      "2025-01-07 09:41:51,753 - INFO - Task 8 Accuracy: 91.36%\n",
      "2025-01-07 09:41:51,753 - INFO - Task 9 Accuracy: 91.22%\n",
      "2025-01-07 09:41:51,755 - INFO - Task 10 Accuracy: 90.84%\n",
      "2025-01-07 09:41:51,756 - INFO - Final Average Accuracy: 91.09%\n"
     ]
    }
   ],
   "source": [
    "# Load the YAML config as a plain text file\n",
    "with open(\"../configs/permuted_mnist.yaml\", \"r\") as f:\n",
    "    config_str = f.read()\n",
    "\n",
    "# Replace Hydra-style placeholders and convert backslashes to forward slashes (e.g. Windows-like, change for Linux/MacOS)\n",
    "cwd = os.getcwd().replace(\"\\\\\", \"/\")\n",
    "config_str = config_str.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "\n",
    "# Load the updated config into OmegaConf\n",
    "config_pmnist = OmegaConf.create(config_str)\n",
    "\n",
    "# Dynamically resolve Hydra-style paths\n",
    "config_pmnist.data.data_root = config_pmnist.data.data_root.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "config_pmnist.hydra.run.dir = config_pmnist.hydra.run.dir.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(config=config_pmnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Function for Split CIFAR-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main training function\n",
    "def main(config):\n",
    "    \"\"\"\n",
    "    Main training function for Split CIFAR-10 multitask joint training.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object loaded from YAML.\n",
    "    \"\"\"\n",
    "    save_dir = config.hydra.run.dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    logging.info(f\"Saving results to {save_dir}\")\n",
    "\n",
    "    # Create Split CIFAR-10 dataset\n",
    "    split_cifar10 = CL_CIFAR10(\n",
    "        classes_per_task=config.data.classes_per_task,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        seed=config.data.seed,\n",
    "    )\n",
    "    split_cifar10.setup_tasks(\n",
    "        batch_size=config.data.batch_size,\n",
    "        data_root=config.data.data_root,\n",
    "        num_workers=config.data.num_workers,\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNN(\n",
    "        width=config.model.width,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        classes_per_task=config.data.classes_per_task,\n",
    "    )\n",
    "    model.to(config.training.device)\n",
    "\n",
    "    # Initialize loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=config.optimizer.lr,\n",
    "        momentum=config.optimizer.momentum,\n",
    "        weight_decay=config.optimizer.weight_decay,\n",
    "        nesterov=config.optimizer.nesterov,\n",
    "    )\n",
    "\n",
    "    # Initialize joint trainer\n",
    "    trainer = JointTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        save_dir=save_dir,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        num_epochs=config.training.num_epochs,\n",
    "        log_interval=config.training.log_interval,\n",
    "        eval_freq=config.training.eval_freq,\n",
    "        task_il=True,  # Set to True for Split CIFAR-10\n",
    "        checkpoint_freq=config.training.checkpoint_freq,\n",
    "        seed=config.training.seed,\n",
    "        scheduler=None,\n",
    "        device=config.training.device,\n",
    "        use_wandb=config.wandb.enabled,\n",
    "        wandb_project=config.wandb.project,\n",
    "        wandb_config=OmegaConf.to_container(config, resolve=True),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Train and evaluate jointly on all tasks\n",
    "        test_accuracies, test_losses = trainer.train_and_evaluate(\n",
    "            cl_dataset=split_cifar10\n",
    "        )\n",
    "\n",
    "        # Calculate and log final metrics\n",
    "        final_accuracies = [test_accuracies[task_id][-1] for task_id in range(config.data.num_tasks)]\n",
    "        avg_accuracy = np.mean(final_accuracies)\n",
    "        \n",
    "        logging.info(\"\\n=== Final Results ===\")\n",
    "        for task_id in range(config.data.num_tasks):\n",
    "            logging.info(f\"Task {task_id + 1} Accuracy: {final_accuracies[task_id]:.2f}%\")\n",
    "        logging.info(f\"Average Accuracy across all tasks: {avg_accuracy:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training and evaluation for Split CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 09:00:07,691 - INFO - Saving results to c:/Users/rufat/cf-tiny-subspaces/notebooks/../results/split_cifar10/subspace-None/k-10/batch_size-128/width-32/lr-0.001/seed-42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrasadlii\u001b[0m (\u001b[33mml-projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\wandb\\run-20250107_090144-mp0a6dtp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-projects/split_cifar10None/runs/mp0a6dtp' target=\"_blank\">balmy-wildflower-2</a></strong> to <a href='https://wandb.ai/ml-projects/split_cifar10None' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-projects/split_cifar10None' target=\"_blank\">https://wandb.ai/ml-projects/split_cifar10None</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-projects/split_cifar10None/runs/mp0a6dtp' target=\"_blank\">https://wandb.ai/ml-projects/split_cifar10None/runs/mp0a6dtp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 09:01:49,312 - INFO - Starting joint training on 5 tasks\n",
      "Epoch 1/5: 100%|██████████| 79/79 [00:09<00:00,  8.36it/s, loss=3.3124, acc=63.12%]\n",
      "2025-01-07 09:03:30,740 - INFO - \n",
      "Epoch 1/5\n",
      "2025-01-07 09:03:30,744 - INFO - Average Loss: 0.6732\n",
      "2025-01-07 09:03:30,744 - INFO - Average Accuracy: 59.27%\n",
      "2025-01-07 09:03:30,745 - INFO - Time: 98.30s\n",
      "Evaluating Task 0: 100%|██████████| 16/16 [00:15<00:00,  1.02it/s]\n",
      "Evaluating Task 1: 100%|██████████| 16/16 [00:16<00:00,  1.02s/it]\n",
      "Evaluating Task 2: 100%|██████████| 16/16 [00:17<00:00,  1.12s/it]\n",
      "Evaluating Task 3: 100%|██████████| 16/16 [00:17<00:00,  1.08s/it]\n",
      "Evaluating Task 4: 100%|██████████| 16/16 [00:16<00:00,  1.06s/it]\n",
      "2025-01-07 09:04:54,941 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:04:54,943 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_0.pt\n",
      "2025-01-07 09:04:54,947 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_0.pt\n",
      "Epoch 2/5: 100%|██████████| 79/79 [00:17<00:00,  4.48it/s, loss=3.1548, acc=63.91%]\n",
      "2025-01-07 09:06:48,846 - INFO - \n",
      "Epoch 2/5\n",
      "2025-01-07 09:06:48,848 - INFO - Average Loss: 0.6379\n",
      "2025-01-07 09:06:48,849 - INFO - Average Accuracy: 65.26%\n",
      "2025-01-07 09:06:48,849 - INFO - Time: 110.98s\n",
      "Evaluating Task 0: 100%|██████████| 16/16 [00:16<00:00,  1.03s/it]\n",
      "Evaluating Task 1: 100%|██████████| 16/16 [00:17<00:00,  1.07s/it]\n",
      "Evaluating Task 2: 100%|██████████| 16/16 [00:16<00:00,  1.05s/it]\n",
      "Evaluating Task 3: 100%|██████████| 16/16 [00:19<00:00,  1.20s/it]\n",
      "Evaluating Task 4: 100%|██████████| 16/16 [00:18<00:00,  1.15s/it]\n",
      "2025-01-07 09:08:16,935 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:08:16,936 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_1.pt\n",
      "2025-01-07 09:08:16,937 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_1.pt\n",
      "Epoch 3/5: 100%|██████████| 79/79 [00:34<00:00,  2.31it/s, loss=3.0080, acc=67.19%]\n",
      "2025-01-07 09:10:44,345 - INFO - \n",
      "Epoch 3/5\n",
      "2025-01-07 09:10:44,348 - INFO - Average Loss: 0.6046\n",
      "2025-01-07 09:10:44,349 - INFO - Average Accuracy: 68.44%\n",
      "2025-01-07 09:10:44,349 - INFO - Time: 144.13s\n",
      "Evaluating Task 0: 100%|██████████| 16/16 [00:17<00:00,  1.07s/it]\n",
      "Evaluating Task 1: 100%|██████████| 16/16 [00:18<00:00,  1.18s/it]\n",
      "Evaluating Task 2: 100%|██████████| 16/16 [00:19<00:00,  1.22s/it]\n",
      "Evaluating Task 3: 100%|██████████| 16/16 [00:18<00:00,  1.17s/it]\n",
      "Evaluating Task 4: 100%|██████████| 16/16 [00:17<00:00,  1.08s/it]\n",
      "2025-01-07 09:12:15,870 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:12:15,874 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_2.pt\n",
      "2025-01-07 09:12:15,875 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_2.pt\n",
      "Epoch 4/5: 100%|██████████| 79/79 [00:11<00:00,  6.91it/s, loss=2.8351, acc=70.31%]\n",
      "2025-01-07 09:14:12,563 - INFO - \n",
      "Epoch 4/5\n",
      "2025-01-07 09:14:12,564 - INFO - Average Loss: 0.5787\n",
      "2025-01-07 09:14:12,566 - INFO - Average Accuracy: 69.72%\n",
      "2025-01-07 09:14:12,567 - INFO - Time: 113.23s\n",
      "Evaluating Task 0: 100%|██████████| 16/16 [00:17<00:00,  1.06s/it]\n",
      "Evaluating Task 1: 100%|██████████| 16/16 [00:16<00:00,  1.05s/it]\n",
      "Evaluating Task 2: 100%|██████████| 16/16 [00:18<00:00,  1.19s/it]\n",
      "Evaluating Task 3: 100%|██████████| 16/16 [00:20<00:00,  1.31s/it]\n",
      "Evaluating Task 4: 100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n",
      "2025-01-07 09:15:44,584 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:15:44,587 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_3.pt\n",
      "2025-01-07 09:15:44,595 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_3.pt\n",
      "Epoch 5/5: 100%|██████████| 79/79 [00:10<00:00,  7.24it/s, loss=2.7302, acc=70.47%]\n",
      "2025-01-07 09:17:42,692 - INFO - \n",
      "Epoch 5/5\n",
      "2025-01-07 09:17:42,698 - INFO - Average Loss: 0.5582\n",
      "2025-01-07 09:17:42,699 - INFO - Average Accuracy: 71.42%\n",
      "2025-01-07 09:17:42,700 - INFO - Time: 114.89s\n",
      "Evaluating Task 0: 100%|██████████| 16/16 [00:19<00:00,  1.19s/it]\n",
      "Evaluating Task 1: 100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n",
      "Evaluating Task 2: 100%|██████████| 16/16 [00:20<00:00,  1.27s/it]\n",
      "Evaluating Task 3: 100%|██████████| 16/16 [00:20<00:00,  1.25s/it]\n",
      "Evaluating Task 4: 100%|██████████| 16/16 [00:16<00:00,  1.04s/it]\n",
      "2025-01-07 09:19:16,797 - INFO - Best model saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_best.pt\n",
      "2025-01-07 09:19:16,798 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_4.pt\n",
      "2025-01-07 09:19:16,799 - INFO - Checkpoint saved: c:\\Users\\rufat\\cf-tiny-subspaces\\notebooks\\..\\results\\split_cifar10\\subspace-None\\k-10\\batch_size-128\\width-32\\lr-0.001\\seed-42\\models\\model_epoch_4.pt\n",
      "2025-01-07 09:19:16,802 - INFO - \n",
      "Training completed in 1047.49s\n",
      "2025-01-07 09:19:16,802 - INFO - Best average accuracy: 72.40%\n",
      "2025-01-07 09:19:16,815 - INFO - \n",
      "=== Final Results ===\n",
      "2025-01-07 09:19:16,818 - INFO - Task 1 Accuracy: 87.70%\n",
      "2025-01-07 09:19:16,819 - INFO - Task 2 Accuracy: 64.45%\n",
      "2025-01-07 09:19:16,820 - INFO - Task 3 Accuracy: 64.15%\n",
      "2025-01-07 09:19:16,821 - INFO - Task 4 Accuracy: 64.90%\n",
      "2025-01-07 09:19:16,822 - INFO - Task 5 Accuracy: 80.80%\n",
      "2025-01-07 09:19:16,822 - INFO - Average Accuracy across all tasks: 72.40%\n"
     ]
    }
   ],
   "source": [
    "# Load the YAML config as a plain text file\n",
    "with open(\"../configs/split_cifar10.yaml\", \"r\") as f:\n",
    "    config_str = f.read()\n",
    "\n",
    "# Replace Hydra-style placeholders and convert backslashes to forward slashes (e.g. Windows-like, change for Linux/MacOS)\n",
    "cwd = os.getcwd().replace(\"\\\\\", \"/\")\n",
    "config_str = config_str.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "\n",
    "# Load the updated config into OmegaConf\n",
    "config_scifar10 = OmegaConf.create(config_str)\n",
    "\n",
    "# Dynamically resolve Hydra-style paths\n",
    "config_scifar10.data.data_root = config_scifar10.data.data_root.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "config_scifar10.hydra.run.dir = config_scifar10.hydra.run.dir.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(config=config_scifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main training function for Split CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main training function\n",
    "def main(config):\n",
    "    \"\"\"\n",
    "    Main training function for Split CIFAR-100 multitask joint training.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object loaded from YAML.\n",
    "    \"\"\"\n",
    "    save_dir = config.hydra.run.dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    logging.info(f\"Saving results to {save_dir}\")\n",
    "\n",
    "    # Create Split CIFAR-100 dataset\n",
    "    split_cifar100 = CL_CIFAR100(\n",
    "        classes_per_task=config.data.classes_per_task,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        seed=config.data.seed,\n",
    "    )\n",
    "    split_cifar100.setup_tasks(\n",
    "        batch_size=config.data.batch_size,\n",
    "        data_root=config.data.data_root,\n",
    "        num_workers=config.data.num_workers,\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNN(\n",
    "        width=config.model.width,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        classes_per_task=config.data.classes_per_task,\n",
    "    )\n",
    "    model.to(config.training.device)\n",
    "\n",
    "    # Initialize loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=config.optimizer.lr,\n",
    "        momentum=config.optimizer.momentum,\n",
    "        weight_decay=config.optimizer.weight_decay,\n",
    "        nesterov=config.optimizer.nesterov,\n",
    "    )\n",
    "\n",
    "    # Initialize joint trainer\n",
    "    trainer = JointTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        save_dir=save_dir,\n",
    "        num_tasks=config.data.num_tasks,\n",
    "        num_epochs=config.training.num_epochs,\n",
    "        log_interval=config.training.log_interval,\n",
    "        eval_freq=config.training.eval_freq,\n",
    "        task_il=True,  # Set to True for Split CIFAR-100\n",
    "        checkpoint_freq=config.training.checkpoint_freq,\n",
    "        seed=config.training.seed,\n",
    "        scheduler=None,\n",
    "        device=config.training.device,\n",
    "        use_wandb=config.wandb.enabled,\n",
    "        wandb_project=config.wandb.project,\n",
    "        wandb_config=OmegaConf.to_container(config, resolve=True),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Train and evaluate jointly on all tasks\n",
    "        test_accuracies, test_losses = trainer.train_and_evaluate(\n",
    "            cl_dataset=split_cifar100\n",
    "        )\n",
    "\n",
    "        # Calculate and log final metrics\n",
    "        final_accuracies = [test_accuracies[task_id][-1] for task_id in range(config.data.num_tasks)]\n",
    "        avg_accuracy = np.mean(final_accuracies)\n",
    "        \n",
    "        logging.info(\"\\n=== Final Results ===\")\n",
    "        for task_id in range(config.data.num_tasks):\n",
    "            logging.info(f\"Task {task_id + 1} Accuracy: {final_accuracies[task_id]:.2f}%\")\n",
    "        logging.info(f\"Average Accuracy across all tasks: {avg_accuracy:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training and evaluation for Split CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML config as a plain text file\n",
    "with open(\"../configs/split_cifar100.yaml\", \"r\") as f:\n",
    "    config_str = f.read()\n",
    "\n",
    "# Replace Hydra-style placeholders and convert backslashes to forward slashes (e.g. Windows-like, change for Linux/MacOS)\n",
    "cwd = os.getcwd().replace(\"\\\\\", \"/\")\n",
    "config_str = config_str.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "\n",
    "# Load the updated config into OmegaConf\n",
    "config_scifar100 = OmegaConf.create(config_str)\n",
    "\n",
    "# Dynamically resolve Hydra-style paths\n",
    "config_scifar100.data.data_root = config_scifar100.data.data_root.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "config_scifar100.hydra.run.dir = config_scifar100.hydra.run.dir.replace(\"${hydra:runtime.cwd}\", cwd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(config=config_scifar100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
